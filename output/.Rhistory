sigma1=5,sigma2=5
)
sim <- emperical.size(R=10000,
mu1=10,mu2=10,
sigma1=5,sigma2=5
)
sim$emperical.size
sim$statistic
sim$empirical.size
prostate <- read.table("D:/Lab6.txt")
head(prostate)
prostate$Y <- ifelse(prostate$Y==8,1,0)
head(prostate)
model <- glm(Y~X1+X2+X3+X4+X5+X6+X7,
data=prostate,
family=binomial(link = "logit")
)
model
est = sum(model$coefficients*c(1, 21.3, 8.4, 48.4, 68, 4.7, 0, 3.2))
y_est = exp(est)/(1+exp(est))
y_est
logistic.NLL = function(beta, data = prostate){
est = c()
for(i in 1:nrow(data))
est = c(est, beta[1]+sum(beta[2:length(beta)]*data[i,1:length(beta)-1]))
l = 0
for(j in 1:length(est))
l = l + data[j, 8]*est[j] - log(1 + exp(est[j]))
return(-l)
}
logistic.NLL(beta=rep(0,8))
I = matric(c(1,0,1,0),nrow=2)
I = matrix(c(1,0,1,0),nrow=2)
I
I = matrix(c(1,0,0,1),nrow=2)
I
solve(I)
Newtons.Method <- function(f, x0, max.iter = 200, stopping.deriv = 0.001) {
n    <- length(x0)
xmat <- matrix(0, nrow = n, ncol = max.iter)
xmat[,1] <- x0
for (k in 2:max.iter) {
# Calculate the gradient
grad.cur <- grad(f, xmat[ ,k-1])
hes.cur = hessian(f, xmat[ ,k-1])
update = solve(hes.cur)%*%grad.cur
# Should we stop?
if (all(abs(grad.cur) < stopping.deriv)) {
k <- k-1; break
}
# Move in the opposite direction of the grad
xmat[ ,k] <- xmat[ ,k-1] - update
}
xmat <- xmat[ ,1:k] # Trim
return(list(x = xmat[,k], xmat = xmat, k = k))
}
result = Newtons.Method(logistic.NLL, rep(0,8))
library(tibble)
df <- tibble(
x = 1:3,
y = sample(seq(1,5,by=2),3),
z = rnorm(3)
)
df
tribble(df)
?tribble
df["x"]
df[["x"]]
library(ggplot2)
ggplot(data = mpg) +
geom_point(mapping = aes(x=displ, y=hwy), color="blue")
ggplot(data = mpg) +
geom_point(mapping = aes(x=displ, y=hwy))
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_grid(drv ~ class)
1:3%>%map_dbl(.,log)
library(purrr)
1:3%>%map_dbl(.,log)
?melt
?t.test
sample(1:10)
sample(1:10,3)
sample(1:10,3,replace = T)
sample(1:10,3,replace = F)
?predict
library (ISLR )
summary ( Smarket)
pairs ( Smarket )
cor ( Smarket [,-9])
head(Smart[,9])
Smart[1:10,9]
head(Smarket[,9])
attach ( Smarket )
?attech
?attach
plot( Volume )
glm . fit =glm ( Direction∼Lag1+ Lag2+ Lag3+Lag4+ Lag5+Volume ,
data=Smarket , family = binomial )
glm . fit =glm ( Direction~ Lag1+ Lag2+ Lag3+Lag4+ Lag5+Volume, data=Smarket, family = binomial )
glm.fit =glm ( Direction~ Lag1+ Lag2+ Lag3+Lag4+ Lag5+Volume, data=Smarket, family = binomial )
summary (glm .fit )
summary (glm.fit)
contrasts ( Direction )
Direction
?contrasts
?contrasts
library (MASS )
lda . fit =lda ( Direction∼Lag1+Lag2 , data=Smarket ,subset = train )
library (MASS )
lda.fit =lda ( Direction∼Lag1+Lag2 , data=Smarket ,subset = train )
lda.fit =lda ( Direction~Lag1+Lag2 , data=Smarket ,subset = train )
library ( class )
?knn
?exp
pexp(1)
pexp(0)
qexp(0)
qexp(ln(1))
log(1)
log(10)
qexp(log(1))
pexp(log(1))
?rexp
pexp(1)
qexp(1)
dexp(1)
?curve
curve(dexp, from = 0, to = 4)
point(1, dexp(1), col = red)
points(1, dexp(1), col = red)
points(1, dexp(1), col = "red")
curve(dexp, from = 0, to = 4)
points(1, dexp(1), col = "red")
points(2, dexp(2), col = "red")
points(4, dexp(4), col = "red")
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
install.packages("rvest")
library(rvest)
library(xml2)
library(rvest)
install.packages("qdap")
library(qdap)
library(qdapDictionaries)
library(qdapRegex)
library(qdapTools)
library(RColorBrewer)
library(qdap)
install.packages("qdap")
library(qdap)
install.packages("sentimentr")
library(sentimentr)
install.packages("gplots")
library(gplots)
library(gplots)
install.packages("syuzhet")
install.packages("factoextra")
library(shiny)
shinyApp(
ui = fluidPage(
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('speech1', 'Speech 1',
speeches,
selected=speeches[5])),
column(4, selectInput('speech2', 'Speech 2', speeches,
selected=speeches[9])),
column(4, sliderInput('nwords', 'Number of words', 3,
min = 20, max = 200, value=100, step = 20))
),
fluidRow(
plotOutput('wordclouds', height = "400px")
)
),
server = function(input, output, session) {
# Combine the selected variables into a new data frame
selectedData <- reactive({
list(dtm.term1=ff.dtm$term[ff.dtm$document==as.character(input$speech1)],
dtm.count1=ff.dtm$count[ff.dtm$document==as.character(input$speech1)],
dtm.term2=ff.dtm$term[ff.dtm$document==as.character(input$speech2)],
dtm.count2=ff.dtm$count[ff.dtm$document==as.character(input$speech2)])
})
output$wordclouds <- renderPlot(height = 400, {
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(selectedData()$dtm.term1,
selectedData()$dtm.count1,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech1)
wordcloud(selectedData()$dtm.term2,
selectedData()$dtm.count2,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech2)
})
},
options = list(height = 600)
)
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tydytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
folder.path="../data/inaugurals/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.all<-Corpus(DirSource(folder.path))
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower))
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))
ff.all<-tm_map(ff.all, removePunctuation)
tdm.all<-TermDocumentMatrix(ff.all)
tdm.tidy=tidy(tdm.all)
tdm.overall=summarise(group_by(tdm.tidy, term), sum(count))
wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
dtm <- DocumentTermMatrix(ff.all,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
ff.dtm=tidy(dtm)
library(shiny)
shinyApp(
ui = fluidPage(
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('speech1', 'Speech 1',
speeches,
selected=speeches[5])),
column(4, selectInput('speech2', 'Speech 2', speeches,
selected=speeches[9])),
column(4, sliderInput('nwords', 'Number of words', 3,
min = 20, max = 200, value=100, step = 20))
),
fluidRow(
plotOutput('wordclouds', height = "400px")
)
),
server = function(input, output, session) {
# Combine the selected variables into a new data frame
selectedData <- reactive({
list(dtm.term1=ff.dtm$term[ff.dtm$document==as.character(input$speech1)],
dtm.count1=ff.dtm$count[ff.dtm$document==as.character(input$speech1)],
dtm.term2=ff.dtm$term[ff.dtm$document==as.character(input$speech2)],
dtm.count2=ff.dtm$count[ff.dtm$document==as.character(input$speech2)])
})
output$wordclouds <- renderPlot(height = 400, {
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(selectedData()$dtm.term1,
selectedData()$dtm.count1,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech1)
wordcloud(selectedData()$dtm.term2,
selectedData()$dtm.count2,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech2)
})
},
options = list(height = 600)
)
setwd('C:/Users/sharonsnow/Documents/GitHub/Spring2019-Proj1-xl2785/output/')
HappyM<-read.csv('processed_moments.csv',stringsAsFactors = FALSE)
text = paste(str_trim(HappyM$text), sep = " ", collapse = " ")
library(stringr)
library(RColorBrewer)
library(wordcloud)
setwd('C:/Users/sharonsnow/Documents/GitHub/Spring2019-Proj1-xl2785/output/')
HappyM<-read.csv('processed_moments.csv',stringsAsFactors = FALSE)
text = paste(str_trim(HappyM$text), sep = " ", collapse = " ")
text = strsplit(text,' ')
length(text)
length(text[1])
length(text[[1]])
a = table(text[[1]])
text = strsplit(text,' ')[[1]]
setwd('C:/Users/sharonsnow/Documents/GitHub/Spring2019-Proj1-xl2785/output/')
HappyM<-read.csv('processed_moments.csv',stringsAsFactors = FALSE)
text = paste(str_trim(HappyM$text), sep = " ", collapse = " ")
text = strsplit(text,' ')[[1]]
t = table(text)
t[1,]
dim(t)
t[1]
t = data.frame(table(text))
t[1,]
wordcloud(t$text,t$Freq)
sort(t[1:10,])
sort(t[1:10,2])
wordcloud(t$text[1:100],t$Freq[1:100])
wordcloud(t$text[1:100],t$Freq[1:100], random.color = TRUE)
t[order(t[1:10,2]),]
?order
t = t[order(t[,2]),decreasing = TRUE]
t = t[order(t[,2],decreasing = TRUE),]
wordcloud(t$text[1:100], t$Freq[1:100])
t[1:10,]
wordcloud(t$text[0:100], t$Freq[0:100])
a = t[1:100]
a = t[1:100,]
a[1,]
wordcloud(a$text,a$Freq)
library(wordcloud2)
wordcloud2(a)
wordcloud2(t)
allFreq = paste(str_trim(HappyM$text), sep = " ", collapse = " ")
%>% strsplit( ,' ')[[1]]
allFreq = paste(str_trim(HappyM$text), sep = " ", collapse = " ") %>% strsplit( ,' ')[[1]] %>% data.frame(table( ))
allFreq = paste(str_trim(HappyM$text), sep = " ", collapse = " ") %>%
strsplit(.,' ')[[1]] %>%
data.frame(table( ))
allFreq = paste(str_trim(HappyM$text), sep = " ", collapse = " ") %>%
strsplit(.,' ')[[1]] %>%
data.frame(table(.))
setwd('C:/Users/sharonsnow/Documents/GitHub/Spring2019-Proj1-xl2785/output/')
HappyM<-read.csv('processed_moments.csv',stringsAsFactors = FALSE)
text = paste(str_trim(HappyM$text), sep = " ", collapse = " ")
text = strsplit(text,' ')[[1]]
allFreq = data.frame(table(text))
wordcloud2(allFreq)
setwd('C:/Users/sharonsnow/Documents/GitHub/Spring2019-Proj1-xl2785/output/')
HappyM<-read.csv('processed_moments.csv',stringsAsFactors = FALSE)
text = paste(str_trim(HappyM$text), sep = " ", collapse = " ")
text = strsplit(text,' ')[[1]]
allFreq = data.frame(table(text))
allFreq = allFreq[order(allFreq[,2], decreasing = TRUE),]
wordcloud2(allFreq[1:100])
setwd('C:/Users/sharonsnow/Documents/GitHub/Spring2019-Proj1-xl2785/output/')
HappyM<-read.csv('processed_moments.csv',stringsAsFactors = FALSE)
text = paste(str_trim(HappyM$text), sep = " ", collapse = " ")
text = strsplit(text,' ')[[1]]
allFreq = data.frame(table(text))
allFreq = allFreq[order(allFreq[,2], decreasing = TRUE),]
wordcloud2(allFreq[1:100,])
?wordcloud2
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(.,' ')[[1]] %>%
data.frame(table(.))
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(.,' ')[[1]]
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(' ')[[1]] %>%
data.frame(table(.))
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(split = ' ')[[1]] %>%
data.frame(table(.))
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
data.frame(table(.))
a
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(., split = ' ')[[1]] %>%
data.frame(table(.))
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ")
strsplit(a, split = ' ')[[1]]
library(tidyverse)
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(., split = ' ')
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>%
.[[1]]
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>%
.[[1]] %>%
data.frame(table(.))
a = a[order(a[,2], decreasing = TRUE),]
wordcloud2(a[1:50,])
a= paste(str_trim(HappyM$text), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>%
.[[1]] %>%
data.frame(table(.))
a= paste(str_trim(HappyM$text[1:10,]), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>%
.[[1]] %>%
data.frame(table(.))
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>%
.[[1]] %>%
data.frame(table(.))
a = a[order(a[,2], decreasing = TRUE),]
wordcloud2(a)
a
paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>%
.[[1]]
paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>%
.[[1]] %>%
data.frame(table(.))
paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>%
.[[1]] %>%
table(.)
a= paste(str_trim(HappyM$text[1:10]), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>%
.[[1]] %>%
table(.) %>% data.frame(.)
a = a[order(a[,2], decreasing = TRUE),]
wordcloud2(a)
a= paste(str_trim(HappyM$text), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>% .[[1]] %>%
table(.) %>% data.frame(.)
a = a[order(a[,2], decreasing = TRUE),]
wordcloud2(a[1:100,])
a[1,]
wordcloud2(a[1:100,])
a= paste(str_trim(HappyM$text), sep = " ", collapse = " ") %>%
strsplit(., split = ' ') %>% .[[1]] %>%
table(.) %>% data.frame(.)
a = a[order(a[,2], decreasing = TRUE),]
wordcloud2(a[1:100,])
a[which(a[,1]=="mate"),]
b = grep("son",text[1:10])
b
text[5]
grep("son",HappyM$text[1:10])
b = grep("mate",HappyM$text)
length(b)
length(grep("mate",text))
length(grep("son",text))
a[which(a[1,]=="son"),]
a[which(a[,1]=="son"),]
a[which(a[,1]=="sons"),]
a[which(a[,1]=="grandson"),]
a[which(a[,1]=="song"),]
b = grep("son ",HappyM$text)
length(b)
b = grep(" son ",HappyM$text)
length(b)
b = grep("daughter",HappyM$text)
length(b)
a[which(a[,1]=="daughter"),]
b = grep("granddaughter",HappyM$text)
length(b)
a[which(a[,1]=="daughters"),]
gregexpr("a[a-z]", "Alabama")
b = grep(HappyM$text, pattern = "son")
length(b)
b = grep(HappyM$text, pattern = "[d]?son")
length(b)
b = grep(HappyM$text, pattern = "[d]?\son")
b = grep(HappyM$text, pattern = "Son")
length(b)
b = grep(HappyM$cleaned_hm, pattern = " son ")
length(b)
b = grep(HappyM$text, pattern = "^son")
length(b)
b = grep(HappyM$text, pattern = " son ")
length(b)
b = grep(HappyM$text, pattern = " son$")
length(b)
allFreq[50,]
wordcloud2(allFreq[1:200,])
wordcloud2(allFreq[1:200,])
allFreq[100,]
allFreq[200,]
